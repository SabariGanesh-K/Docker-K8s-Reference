
In Kubernetes, a pod is the smallest and most basic unit of deployment. It represents a single instance of a running process in a cluster. A pod can contain one or more tightly coupled containers that share the same network namespace, IPC (inter-process communication) namespace, and storage volumes.

The necessity and use cases of Kubernetes pods are as follows:

Encapsulation of Containers: Pods provide a logical grouping and encapsulation of containers. Containers within a pod are co-located on the same node and can easily communicate with each other using localhost. This allows related containers to share resources, dependencies, and data, making it easier to manage and deploy multi-container applications.

Atomic Unit of Scheduling: Pods are the unit of scheduling in Kubernetes. When scheduling containers, Kubernetes schedules entire pods rather than individual containers. This ensures that all containers within a pod are scheduled and deployed together on the same node, maintaining their co-location and enabling efficient communication.

Shared Network and Storage: Containers within a pod share the same network namespace, meaning they can communicate with each other over localhost without exposing ports externally. They can also share the same storage volumes, allowing them to access and manipulate shared data. This makes pods suitable for applications with tightly coupled or interdependent containers.

Scaling and Horizontal Pod Autoscaling: Pods can be scaled horizontally to handle increased traffic or workload demands. You can create multiple replica pods, which are identical copies of the same pod, and distribute them across different nodes. Kubernetes can automatically scale the number of replicas based on resource usage or other metrics using Horizontal Pod Autoscaling (HPA).

Load Balancing and Service Discovery: Pods can be associated with a service in Kubernetes. The service acts as a stable endpoint for accessing the pods. Kubernetes manages load balancing across the pods associated with a service, distributing incoming traffic to the available replicas. This allows for easy service discovery and load balancing within the cluster.

Blue-Green and Canary Deployments: Pods are used in deployment strategies such as blue-green deployments and canary deployments. In a blue-green deployment, a new version of a pod is deployed alongside the existing version, and traffic is switched between them. In a canary deployment, a small percentage of traffic is routed to the new version for testing and validation before scaling it up to all pods.

Sidecar Containers: Pods can be used to deploy sidecar containers that provide additional functionality or support to the main container. Sidecar containers run alongside the main container within the same pod, enabling tasks such as logging, monitoring, or proxying to be handled by separate containers in the same context.

In summary, Kubernetes pods are necessary for encapsulating and managing containers as a cohesive unit. They facilitate the deployment, scaling, and management of containerized applications, while allowing containers within a pod to share network and storage resources. Pods provide the foundational building block for scheduling, scaling, and managing containerized workloads in Kubernetes.

# Let’s first create a node running Nginx by using the imperative way.

## Create the pod

    kubectl run mynginx --image=nginx

## Get a list of running pods

    kubectl get pods

## Get more info

    kubectl get pods -o wide
    kubectl describe pod mynginx

## Delete the pod

    kubectl delete pod mynginx

## Create a pod running BusyBox

Let’s now create a node running BusyBox, this time attaching bash to our terminal.

    kubectl run mybox --image=busybox -it -- /bin/sh

## List the folders and use command

    ls
    echo -n 'A Secret' | base64
    exit

## Cleanup

    kubectl delete pod mybox

## Create a pod using the declarative way

Let’s now create a node using a YAML file.

    kubectl create -f myapp.yaml

## Get some info

    kubectl get pods -o wide
    kubectl describe pod myapp-pod

## Attach our terminal

    kubectl exec -it myapp-pod -- bash

Print the DBCON environment variable that was set in the YAML file.

    echo $DBCON

## Detach from the instance

    exit

## Cleanup

    kubectl delete -f myapp.yaml


<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>
## SAMPLE YAML 
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
    type: front-end
spec:
  containers:
  - name: nginx-container
    image: nginx
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 250m
        memory: 256Mi    
    ports:
    - containerPort: 80
      name: http
      protocol: TCP
    env:
    - name: DBCON
      value: myconnectionstring


